<!DOCTYPE html>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
<title>SpLU 2018 by SpLU</title>
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link
    href='http://fonts.googleapis.com/css?family=Open+Sans:400,700'
rel='stylesheet' type='text/css'>
<link rel="stylesheet"
    href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
    integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7"
crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css"
href="stylesheets/github-light.css" media="screen">

<!-- Latest compiled and minified CSS -->
 

  </head>
  <body>
<section class="page-header">

      <h1 class="project-name">SpLU 2018</h1>
      <h2 class="project-tagline">First International Workshop on Spatial Language Understanding</h2>
<h2  class="project-tagline">In conjunction with The 16th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies <a href="https://aaai.org/Conferences/AAAI/aaai18.php">(NAACL-HLT 2018)</a>, June 1â€“6, 2018, New Orleans, Louisiana, USA.</h2>
<br>

</section>
<section>
  <!-- Static navbar -->
      <nav class="navbar navbar-default">
        <div class="container-fluid">
          <div class="navbar-header">
            <butfton type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
              <span class="sr-only">Toggle navigation</span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
           
          </div>
          <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li class="active"><a href="#topics">Topics</a></a></li>
        <li><a href="#schedule">Schedule</a></li>
              <li><a href="#invitedSpeakers">Invited Speakers</a></li>
	      <li><a href="#submission-info">Submission</a></li>
         <li><a href="#important-dates">Important Dates</a></li>
	      <!--li><a href="#demos">Demos</a></li-->
	      <!--li><a href="#panel">Panel</a></li-->
	      <!--li><a href="#submission-info">Submission</a></li-->
	      <li><a href="#organizers">Organizers</a></li>
         </ul>
            </div><!--/.nav-collapse -->
        </div><!--/.container-fluid -->
      </nav>

</section>


<section class="main-content">

<h2>Overview</h2>

<p>
One of the essential functions of natural language is to express spatial relationships between objects. Linguistic constructs can encode highly complex, relational structures of objects, spatial relations between them, and patterns of motion through space relative to some reference point. Spatial language understanding is useful in many areas of research endeavors relating to and/or making use of human language, including robotics, navigation, geographic information systems, traffic management, natural language understanding and translation, and query answering systems. Compared to other semantically specialized linguistic tasks, standardizing tasks related to spatial language seems to be more challenging as it is harder to obtain an agreeable set of concepts and relationships and a formal spatial meaning representation that is domain independent, as an example this could be compared to temporal relations. This has made research results on spatial language learning and reasoning diverse, task-specific and, to some extent, not comparable. While formal meaning representation is a general issue for language understanding, formalizing spatial concepts and building formal reasoning models based on those constitute challenging research problems with a wealth of prior foundational research that can be exploited and linked to language understanding. Existing qualitative and quantitative representation and reasoning models can be used for investigation of interoperabiltiy of machine learning and reasoning over spatial semantics. Research endeavors in this area could provide insights into many challenges of language understanding in general. Spatial semantics is also very well-connected and relevant to visualization of natural language, central to dealing with configurations in the physical world and motivating a combination of vision and language for richer spatial understanding. 
This workshop highlights some of the above aspects of computational spatial language understanding including the following four areas: </p>

<ol>

<li> Spatial Language Meaning Representation (Continuous, Symbolic)</li>
<li> Spatial Language Learning </li>
<li> Spatial Language Reasoning </li>
<li> Combining Vision and Language for Spatial Understanding</li>
</ol>

<p>Spatial Language Meaning Representation and Ontologies includes cognitive and linguistically motivated spatial knowledge representation and ontologies, qualitative and quantitative representation models used for meaning representation of language, related annotation schemes and efforts for creating specialized corpora. Moreover, continuous meaning representations for spatial concepts is another aspect to be highlighted in the workshop. Spatial Language Learning considers symbolic and sub-symbolic techniques and computational models for spatial information extraction, semantic parsing, spatial co-reference within a global context that includes discourse and pragmatics from data or formal models.

Regarding the reasoning aspect, the workshop emphasizes the role of qualitative and quantitative formal representations in helping spatial reasoning based on natural language and the possibility of learning such representations from data; whether we need these formal representations to support reasoning or there are other alternative ideas.  

For the multimodality aspect, answers to questions such as the following will be discussed: (1) Which representations are appropriate for different modalities and which ones are modality independent? (2) How can we exploit visual information for spatial language learning and reasoning? All related applications are welcome, including text to scene conversion, spatial and visual question answering, spatial understanding in multimodal setting for robotics and navigation tasks, etc. 

The workshop aims to initiate discussions across fields dealing with spatial language along with other modalities. The desired outcome is identification of shared as well as unique challenges, problems and future directions across the fields and various application domains related to spatial language understanding. The specific areas include but are not limited to: 
</p>

<ul>
<li>Spatial meaning representations, ontologies, annotation schemes, linguistic corpora.</li>
<li>Spatial information extraction from natural language.</li>
<li>Spatial information extraction in robotics, multimodal environments, navigational instructions.</li>
<li>Text mining for spatial information in GIS systems.</li>
<li>Spatial information in query answering systems, answering locative questions, such as where-questions.</li>
<li>Spatial information for visual question answering</li>
<li>Quantitative and qualitative reasoning with spatial information</li>
<li>Spatial reasoning based on natural language</li>
<li>Spatial reasoning based on multimodal information (vision and language)</li>
<li>Extraction of spatial common sense knowledge</li>
<li>Visualization of spatial language in 2-D and 3-D</li>
<li>Spatial natural language generation</li>
<li>Spatial language grounding</li>
</ul>

<a id="invitedSpeakers" class="anchor" href="#invitedSpeakers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Invited Speakers</h2>

<ul>
 <li> 
   <font size="3" color="black"><b><a href="https://engineering.leeds.ac.uk/staff/76/">Anthony G Cohn</a>, University of Leeds</b></font> 
   <br />
   <b>Title: Natural Language Acquisition and Grounding for Embodied Robotic Systems</b>
   <br />
   Abtract: We present a cognitively plausible novel framework capable of learning the grounding in visual semantics and the grammar of natural language commands given to a robot in a table top environment. The input to the system consists of video clips of a manually controlled robot arm, paired with natural language commands describing the action. No prior knowledge is assumed about the meaning of words, or the structure of the language, except that there are different classes of words (corresponding to observable actions, spatial relations, and objects and their observable properties). The learning process automatically clusters the continuous perceptual spaces into concepts corresponding to linguistic input. A novel relational graph representation is used to build connections between language and vision. As well as the grounding of language to perception, the system also induces a set of probabilistic grammar rules. The knowledge learned is used to parse new commands involving previously unseen objects.	
</li>
<li> 
   <font size="3" color="black"><b><a href="http://www.cs.rochester.edu/~james/">James F. Allen</a>, IHMC, University of Rochester</b></font> 

</ul>

<a id="submission-info" class="anchor" href="#submission-info" aria-hidden="true"><span class="octicon octicon-link"></span></a>
<h2>Submissions</h2>

We encourage contributions with either a technical paper (NAACL style, 8 pages without references), a position statement (NAACL style, 4 pages maximum) or an abstract of a published work. NAACL Style files available <a href="http://naacl2018.org/call_for_paper.html">here</a>. Please make submissions via Softconf <a href= "https://www.softconf.com/naacl2018/SpLU18/">here</a>.

 <a id="important-dates" class="anchor" href="#accepted-papers" aria-hidden="true"><span class="octicon octicon-link"></span></a><h2>Important Dates</h2>
 <ul>
  <li>SubmissionÂ Deadline: 2 March 2018</li>
  <li>Notification: 2 April 2018 </li>
  <li>Camera Ready deadline: 16 April 2018</li>
  <li>Workshop Day: To be announced </li>
 </ul>
  
<a id="organizers" class="anchor" href="#organizers" aria-hidden="true"><span class="octicon octicon-link"></span></a>

<h2>Organizing Committee</h2>

<table cellspacing="0" cellpadding="0" style="width:100%">
<tr>
<td>
 <li><a href="http://www.cs.tulane.edu/%7Epkordjam/">Parisa Kordjamshidi</a></td>
  <td>Tulane University, <a href="https://www.ihmc.us">IHMC</a></li></td>
  <td> pkordjam@tulane.edu</td>
</tr>
<tr>
<td><li><a href="https://www.ihmc.us/groups/abhatia/">Archna Bhatia</li></td>
<td>IHMC</td>
<td>abhatia@ihmc.us</td>
</tr>

<tr> <td><li><a href="https://www.researchgate.net/profile/Umar_Manzoor">Umar Manzoor</a></li></td> 
<td>Tulane University</td> 
<td>umanzoor@tulane.edu</td>
</tr>

<tr>
<td><li><a href="http://jamespusto.com/">James Pustejovsky</a></li></td> <td>Brandeis University</td>
 <td>jamesp@cs.brandeis.edu</td> 
 </tr>
 <tr>
<td><li><a href="https://people.cs.kuleuven.be/~sien.moens/"> Marie-Francine Moens</a> </li></td> <td>KULeuven</td>
 <td>sien.moens@cs.kuleuven.be</td> 
 </tr>
</table>

<a id="program-commitee" class="anchor" href="#program-commitee" aria-hidden="true"><span class="octicon octicon-link"></span></a>

<h2>Program Committee</h2>
<div>
<table cellspacing="0" cellpadding="0" float="left">
<tr>
<td>
<li>John A. Bateman</td> <td>Universitat Bremen</td></li>
  </tr>
 <tr>
<td><li>Anthony Cohn</td><td>University of Leeds</li></td>
</tr>
  <tr>
<td><li>Steven Bethard</td><td> The University of Arizona</td></li>
</tr>
<tr>
<td>
<li>Raffaella Bernardi</td><td>University of Trento</td></li>
</tr>
<tr>
<td><li>Mehul Bhatt</td><td>Ã–rebro University</li></td>
</tr>
<tr>
<td>
<li> Yonatan Bisk</td> <td>University of Washington</li></td>
</tr>
<tr>
<td><li>Johan Bos</td><td>University of Groningen</li></td>
</tr>
<tr>
<td><li>Joyce Chai</td><td>Michigan State University</li></td>
</tr>
<tr>
<td><li>Angel Xuan Chang</td><td>Stanford University</li></td>
</tr>
<tr>
<td><li>Guillem Collell</td><td> KU Leuven</li></td>
</tr>
<tr>
<td><li>Zoe Falomir</td><td>Universitat Bremen</li></td>
</tr>
<tr>
<td><li>Julia Hockenmaier</td><td>University of Illinois at Urbana-Champaign</li></td>
</tr>
<tr>
<td><li>Inderjeet Mani</td><td>Yahoo Labs</li></td>
</tr>
<tr>
<td><li>Kirk Roberts</td><td>The University of Texas</li></td>
</tr>
<tr>
<td><li>Manolis Savva</td><td>Princeton University</li></td>
</tr>
<tr>
<td><li>Martijn van Otterlo</td><td>Vrije Universiteit Amsterdam</li></td>
</tr>
<tr>
<td><li>Bonnie Dorr</td><td>IHMC</li></td>
</tr>
<tr>
<td><li>Bruno Martins</td><td>University of Lisbon</li></td>
</tr>
<tr>
<td><li>Mari Broman Olsen</td><td>Microsoft</li></td>
</tr>
<tr>
<td><li>Clare Voss</td><td>ARL</li></td>
</tr>

</table>

</div>

    </section>

<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11083511; 
var sc_invisible=1; 
var sc_security="2f97c6cf"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="web analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/11083511/0/2f97c6cf/1/" alt="web
analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>
