<!DOCTYPE html>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
<title>SpLU Invited speakers (Yoav Artzi) </title>
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link
    href='http://fonts.googleapis.com/css?family=Open+Sans:400,700'
rel='stylesheet' type='text/css'>
<link rel="stylesheet"
    href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
    integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7"
crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css"
href="stylesheets/github-light.css" media="screen">

<!-- Latest compiled and minified CSS -->
  </head>
  
<body>
<section class="page-header">
      <h1 class="project-name">SpLU 2020 Invited Speakers</h1>
      <h2 class="speaker">Yoav Artzi</h2>
</section>

<section class="main-content">

<h3>Few-shot Object Reasoning for Robot Instruction Following</h3>

Representation learning models are notoriously opaque and difficult to extend. This particularly limits embodied agents following instructions in continuously-changing environments. This talk focuses on the problem of extending an instruction-following robot's reasoning to new objects, including both their observations and references in text. We define the problem of few-shot language-conditioned object segmentation, and propose an approach that explicitly aligns object references to the space they occupy in the world. We train this method using large-scale automatically generated augmented reality data. We use the segmentation and instruction information to formalize and construct a world map that captures desired behavior around objects, but abstracts over specific object information. We show how integrating this map into a control policy for natural language instruction following with a quadcopter drone allows following instructions with previously unseen objects without any additional training.
</section>


<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11083511; 
var sc_invisible=1; 
var sc_security="2f97c6cf"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="web analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/11083511/0/2f97c6cf/1/" alt="web
analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
</body>
</html>
